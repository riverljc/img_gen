import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
import re
import openai
from openai import OpenAI
import base64
from io import BytesIO
from PIL import Image
import streamlit as st

st.set_page_config(layout="wide")
        
@st.experimental_dialog("æ”¾å¤§åœ–ç‰‡")
def show_dialog(img_name: str):
    # è¼‰å…¥åœ–ç‰‡
    image = Image.open(img_name)
    
    results = re.sub(r'\d+', '', img_name.name[:-4]).replace('  ',' ').split('_')
    
    if(len(results) > 1):
        prompt = results[0]
        tag = results[1]
    else: 
        prompt = results[0]
        tag = results[0]
        
    st.subheader('Prompt: ' + prompt.strip())
    
    width, height = image.size

    # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹
    scale = 0.4

    # è¨ˆç®—æ–°çš„å¯¬åº¦å’Œé«˜åº¦
    new_width = int(width * scale)
    new_height = int(height * scale)

    # èª¿æ•´åœ–ç‰‡å¤§å°
    resized_image = image.resize((new_width, new_height))

    # é¡¯ç¤ºåœ–ç‰‡
    st.image(resized_image)
    
    st.subheader('Tag: ' + tag.strip().replace(' ','/'))
            
    if st.button("é—œé–‰è¦–çª—", key=2):
        st.rerun()

def select_photo():
    st.write('')
    
    st.subheader('å¾åœ–åº«æ‰¾éˆæ„Ÿâ¬‡ï¸â¬‡ï¸')

    # æŒ‡å®šç›®éŒ„è·¯å¾‘
    directory_path = 'data'

    # ä½¿ç”¨ pathlib è®€å–æ‰€æœ‰æª”æ¡ˆ
    files = [file for file in Path(directory_path).iterdir()]
    current_page_images = sorted(files, key=lambda x: x.stat().st_ctime, reverse=True)

    if(len(current_page_images) > 0):
        n_o_i = 8
        
        cols = st.columns(n_o_i)
        
        # æ˜¾ç¤ºå½“å‰é¡µçš„å›¾ç‰‡å’Œå¤é€‰æ¡†
        for i, img in enumerate(current_page_images[:48]):
            current_col = cols[i % n_o_i]
        
            with current_col:
                if st.button(f"åŸåœ–", key=f"enlarge_{i}"):
                    show_dialog(img)
                
                # è¼‰å…¥åœ–ç‰‡
                image = Image.open(img)
                
                width, height = image.size

                # ç¸®æ”¾æ¯”ä¾‹
                scale = 0.15

                # è¨ˆç®—æ–°çš„å¯¬åº¦å’Œé«˜åº¦
                new_width = int(width * scale)
                new_height = int(height * scale)

                # èª¿æ•´åœ–ç‰‡å¤§å°
                resized_image = image.resize((new_width, new_height))

                # é¡¯ç¤ºåœ–ç‰‡
                st.image(resized_image)#, caption=img_name.name[:-18]) 

def filter_words(results: str):
    # å®šç¾©è¦æ’é™¤çš„è©å½™
    excluded_words = {'è«‹', 'å¹«', 'ç”¢', 'ç”¢ç”Ÿ', 'çµ¦', 'å¯å¦', 'åœ–ç‰‡', 'åœ–'}

    ini_words = results.replace('ã€',' ').replace('ã€‚',' ').replace(',',' ').split()
    final_words = [w for w in ini_words if w not in excluded_words]
    return ' '.join(final_words)

def extract_keywords(sentence):
    client = OpenAI()
	
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": f"å¾ä»¥ä¸‹çš„å¥å­ä¸­æå–é‡è¦çš„è©å½™:\n\n{sentence}\n\né‡è¦è©å½™:"}],
        temperature=0,
        max_tokens=50
    )
	
    return filter_words(response.choices[0].message.content)

def base64_to_image(base64_string, save_path=None):
    try:
        image_data = base64.b64decode(base64_string)
        image_buffer = BytesIO(image_data)
        image = Image.open(image_buffer)
        
        if save_path:
            image.save(save_path)
            
        return image
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

if __name__ == '__main__':        
    st.subheader("æ•˜è¿°æ‚¨æƒ³è¦çš„åœ–ç‰‡å…§å®¹ğŸš€")
    text_input = st.text_area('æ•˜è¿°æ‚¨æƒ³è¦çš„åœ–ç‰‡å…§å®¹ï¼š', label_visibility='collapsed')
       
    # å‰µå»ºå…©å€‹åˆ—
    if st.button("ç”Ÿæˆåœ–ç‰‡"):
        if text_input and len(text_input.strip()) > 0:
            text_input = text_input.strip()
            
            tags = extract_keywords(text_input)
            
            n_of_img = 2

            client = OpenAI()
            
            with st.spinner('åœ–ç‰‡ç”Ÿæˆä¸­... è«‹ç¨å€™!'):                 
                for i in range(n_of_img):
                    try:
                        response = client.images.generate(
                            model="dall-e-3",
                            prompt=text_input,
                            size="1024x1792", #"1024x1024","1792x1024"
                            quality="standard",
                            n=1,  # Each call generates one image
                            response_format='b64_json'
                        )

                        image_b64 = response.data[0].b64_json

                        # æ¸…é™¤ç‰¹æ®Šç¬¦è™Ÿï¼Œåªä¿ç•™å­—æ¯ã€ä¸­æ–‡ã€ç©ºç™½å’Œä¸‹åŠƒç·š
                        clean_string = re.sub(r'[^a-zA-Z\u4e00-\u9fff_\s]', '', text_input + '_' + tags)

                        # ä½¿ç”¨ç•¶å‰æ™‚é–“çš„æ™‚é–“æˆ³è¨˜
                        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')

                        # çµ„åˆæœ€çµ‚çš„æª”å
                        f_name = "data/" + clean_string + timestamp + ".png"
                        
                        generated_image = base64_to_image(image_b64, f_name)
                    except openai.APIError as err:
                        err_json = err.response.json()
                        st.error(err_json['error']['message'])            
        else:  # å¦‚æœå…§å®¹ç‚ºç©º
            st.error('è«‹è¼¸å…¥æç¤º!')    
        
    select_photo()
    
